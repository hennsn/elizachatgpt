{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML News\n",
    "\n",
    "- Multi Perspective Evaluations Available on Open LLM Leaderboard: \n",
    "    - https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard\n",
    "\n",
    "\n",
    "- Alternative Large Scale Evaluation Benchmark: \n",
    "    - HELM: https://crfm.stanford.edu/helm/latest/\n",
    "    - unfortunately companies do not do it ... but open source should!\n",
    "\n",
    "\n",
    "- InstructEval: Large Scale Evaluation of Instruction Fine Tuned Models\n",
    "    -  https://arxiv.org/abs/2306.04757\n",
    "\n",
    "\n",
    "- New AMD AI Stack + Huggingface Support:\n",
    "    - https://huggingface.co/blog/huggingface-and-amd\n",
    "\n",
    "\n",
    "- H2O GPT Models: \n",
    "    - chat + web plugin: https://gpt-gm.h2o.ai/\n",
    "    - file upload + chat: https://falcon.h2o.ai/\n",
    "    - models: https://huggingface.co/h2oai/h2ogpt-gm-oasst1-en-2048-falcon-7b-v2\n",
    "\n",
    "- **Studentische Wahlen**\n",
    "    - https://www.uni-jena.de/wahlamt\n",
    "\n",
    "- **Thema Diskussionsveranstaltung**\n",
    "    - Legal aspects of AI and LLMs, Copyright, Watermarking, Autonomous Cars, Alignment Problems,  : I\n",
    "    - Learning, Publishing, Studying, Using AI Systems in University\n",
    "    - Low Ressource LLM Deployments: llama.cpp, webgpu, web-llm, mlc-llm\n",
    "    - How does AI change society? How will it change society in the future? Working in ages of AI, Impact of AI on society: I\n",
    "    \n",
    "---\n",
    "    \n",
    "- 26. Juni\n",
    "    - Diskussionsveranstaltung\n",
    "    \n",
    "- 3. Juli\n",
    "    - Vorträge\n",
    "    - ?\n",
    "    - früher besser als später :) (ab12)\n",
    "\n",
    "---\n",
    "\n",
    "- llama.cpp: https://github.com/ggerganov/llama.cpp\n",
    "- pyllama.cpp: https://github.com/abdeladim-s/pyllamacpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dialog Modelling\n",
    "\n",
    "- Open NLP Book by Dan Jurafsky and James Martin: https://web.stanford.edu/~jurafsky/slp3/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech Acts\n",
    "- In Dialogue text/utterances work as ACTIONS\n",
    "- there are 4 different types of dialog actions (=speech acts)\n",
    "\n",
    "### Grounding\n",
    "- = establishing common ground between dialog partners = feeling of being understood by the other\n",
    "\n",
    "### Dialog Structures\n",
    "- adjacency pairs (e.g. question-answer, utterance-clarification request, ...)\n",
    "\n",
    "### Initiative\n",
    "- single initiated\n",
    "- mixed initiative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule-based Dialog Systems\n",
    "\n",
    "= ELIZA (1966): https://dl.acm.org/doi/10.1145/365153.365168\n",
    "\n",
    "![](https://d3i71xaburhd42.cloudfront.net/763542e63ab6720759d0b9e78fb17416d25efa06/4-Figure2-1.png)\n",
    "\n",
    "![](https://www.researchgate.net/publication/351363891/figure/fig1/AS:1020499173847041@1620317371344/Sample-ELIZA-dialogue-from-Weizenbaum-1966.jpg)\n",
    "\n",
    "\n",
    "**PATTERN MATCHING RULES**: \n",
    "    - match a pattern based on a grammar\n",
    "    - if you matched a pattern -> extract an input(=a keyword) from that pattern and apply a rule that uses that input to return an output\n",
    "    - (see paper)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slot-Filling-based Dialog Systems\n",
    "\n",
    "- Used in task-oriented dialog scenarios e.g. user wants to book a hotel, book a flight, book an appointment with a doctor, ..\n",
    "- Example: https://rasa.com/\n",
    "\n",
    "\n",
    "- **SLOTS**: set of values that the bot has to gain information about, e.g. flight destination, flight time, flight price. When all values of a SLOT are obtained -> we can call a function and serve the user with an answer/response. \n",
    "\n",
    "![](https://ithelp.ithome.com.tw/upload/images/20190919/2010385289dD1y8S2J.png)\n",
    "\n",
    "- **INTENS**: = classification of user inputs into a fixed set of intents\n",
    "- **ACTIONS**: for every intent define \n",
    "\n",
    "![](https://i.ytimg.com/vi/WK7C8pLnfvY/maxresdefault.jpg)\n",
    "\n",
    "![](https://eng.ftech.ai/wp-content/uploads/2019/06/Screen-Shot-2019-06-04-at-18.16.49-1024x542.png)\n",
    "\n",
    "- **State Tracking**: \n",
    "    - SLOTS: keep track of the current values in the slots \n",
    "    - DIALOG HISTORY: keep track of (recent) dialog history, e.g. last 5 turns\n",
    "\n",
    "![](https://smazee.com/uploads/images/rasa-5.png)\n",
    "\n",
    "- **Dialog Policy**: given a set of dialogs (= sequences of intent + action) learn an optimal policy for which action to take optimally for which intent to fill the slots in the shortest amount of time and therefore fullfill the task of the task-oriented dialog optimally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Based Dialog Systems\n",
    "\n",
    "= e.g. ChatGPT (LLM based dialog systems)\n",
    "\n",
    "- **PRE-TRAINING**\n",
    "    - Trillions of tokens, next word prediction\n",
    "\n",
    "![](https://thegradient.pub/content/images/2019/10/lm-1.png)\n",
    "\n",
    "- **ALIGNMENT**: \n",
    "    - Reinforcement Learning from Human Feedback (RLHF)\n",
    "    - DPO = direct preference optimization: https://arxiv.org/abs/2305.18290\n",
    "    - Bayesian Approaches: https://en.wikipedia.org/wiki/Human_Compatiblej, no implementations for llms seen so far\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:1400/1*yCzfUi2CgSl-yW_gYAjDMw.png)\n",
    "\n",
    "![](https://pbs.twimg.com/media/FxdM7muXsAI5MnH.jpg:large)\n",
    "\n",
    "\n",
    "- **PROMPT**: \n",
    "    - system prompt\n",
    "        - example: https://gpt-gm.h2o.ai/\n",
    "    - user input  \n",
    "    - in context learning/few shot learning -> examples in prompt (e.g. for retrieval augmented systems)\n",
    "\n",
    "![](https://preview.redd.it/using-system-message-to-tell-gpt-4-its-an-expert-and-that-a-v0-g9ov2fx2wdqa1.png?width=614&format=png&auto=webp&s=730693ae3bb71febdfad0ac615854325164b0010)\n",
    "\n",
    "![](https://media.arxiv-vanity.com/render-output/6470302/x1.png)\n",
    "\n",
    "- **STATE**: = state representation, usually included in prompt\n",
    "    - sequence state = dialog history\n",
    "        - [\"Hello\", \"Hi, How can I help you?\", ...]\n",
    "    - graph state = e.g. dialog partner, dialog topic = e..g as JSON GRAPH, for us -> this was the state of the visualzation\n",
    "        - {\"Person\": {\"Name\": \"Max\", \"Age\":\"25\", ...}}\n",
    "\n",
    "\n",
    "\n",
    "- **QUERY PRE-PROCESSING**\n",
    "    - query similarity estimation -> fallbacks for bad inputs\n",
    "\n",
    "![](https://inside-machinelearning.com/wp-content/uploads/2021/11/tsne_sentences_embedding_visualization-1.jpeg)\n",
    "\n",
    "- **QUERY POST_PROCESSING**\n",
    "    - query control by second model\n",
    "    - query similarity estimation (=harm) e.g. via sentence bert\n",
    "    - correctness check (current focus of research)\n",
    "\n",
    "\n",
    "**PLUGINS**: \n",
    "- retrieval mechanisms\n",
    "- APIs for external services\n",
    "- langchain: https://github.com/hwchase17/langchain\n",
    "    - in langchain called TOOLS\n",
    "    - = in essence these are function calls and the model uses the output of the function for further iteration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU CODE EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GGML/resolve/main/WizardLM-7B-uncensored.ggmlv3.q4_0.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyllamacpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/content/WizardLM-7B-uncensored.ggmlv3.q4_0.bin\" # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyllamacpp.model import Model\n",
    "\n",
    "model = Model(model_path=model_path, n_ctx=512)\n",
    "\n",
    "prompt = \"how much gravity does the moon have?\"  # @param {type: 'string'}\n",
    "n_threads = 2  # @param {type: 'integer'}\n",
    "n_predict = 45  # @param {type: 'integer'}\n",
    "repeat_last_n = 64  # @param {type: 'integer'}\n",
    "top_k = 40  # @param {type: 'integer'}\n",
    "top_p = 0.95  # @param {type: 'number'}\n",
    "temp = 0.6  # @param {type: 'number'}\n",
    "repeat_penalty = 1.3  # @param {type: 'number'}\n",
    "\n",
    "\n",
    "for token in model.generate(prompt,\n",
    "                                n_threads=n_threads,\n",
    "                                n_predict=n_predict,\n",
    "                                repeat_last_n=repeat_last_n,\n",
    "                                top_k=top_k,\n",
    "                                top_p=top_p,\n",
    "                                temp=temp,\n",
    "                                repeat_penalty=repeat_penalty):\n",
    "    print(token, end='', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
