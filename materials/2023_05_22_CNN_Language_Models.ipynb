{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn']\n",
      "num words:  32033\n",
      "len dictinct characters:  26\n",
      "distinct_characters:  ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Num Characters:  27\n",
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25}\n",
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, '_': 26}\n",
      "{0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z', 26: '_'}\n"
     ]
    }
   ],
   "source": [
    "# PREPARE DATA\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# read words from file\n",
    "#words = open('./english_verbs.txt', 'r').read().splitlines()\n",
    "# alternative dataset: https://github.com/dwyl/english-words\n",
    "#words = open('./words_alpha.txt', 'r').read().splitlines()\n",
    "# alternative dataset: german names\n",
    "words = open('./names.txt', 'r').read().splitlines()\n",
    "\n",
    "print(words[:10])\n",
    "\n",
    "print('num words: ', len(words)) \n",
    "\n",
    "# Prepare Alphabet\n",
    "## count characters \n",
    "dataset_characters = []\n",
    "for word in words:\n",
    "    word_characters = list(word) \n",
    "    dataset_characters.extend(word_characters)\n",
    "distinct_characters = sorted(list(set(dataset_characters)))\n",
    "print('len dictinct characters: ', len(distinct_characters))\n",
    "print('distinct_characters: ', distinct_characters)\n",
    "\n",
    "special_characters = ['_'] # changed to blank only for convenience reasons\n",
    "\n",
    "# ngram characters = distinct characters + start token and end token -> + 2\n",
    "num_characters = len(distinct_characters) + len(special_characters)\n",
    "print('Num Characters: ', num_characters)\n",
    "\n",
    "# create a character to index mapping because it is easier to work with indices when using tensor matrices -> every character gets assigned an index\n",
    "character_to_index_map = {character:index for index, character in enumerate(distinct_characters)}\n",
    "print(character_to_index_map)\n",
    "\n",
    "# add our special characters that symbolize start and end of a word\n",
    "character_to_index_map['_'] = 26\n",
    "print(character_to_index_map)\n",
    "\n",
    "# write characters into the cells to make it look more nicely\n",
    "index_to_character_map = {index:character for character, index in character_to_index_map.items()}\n",
    "print(index_to_character_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25626\n",
      "3203\n",
      "3204\n",
      "torch.Size([182375, 16]) torch.Size([182375])\n",
      "torch.Size([22916, 16]) torch.Size([22916])\n",
      "torch.Size([22855, 16]) torch.Size([22855])\n",
      "________________ ---> c\n",
      "_______________c ---> a\n",
      "______________ca ---> p\n",
      "_____________cap ---> r\n",
      "____________capr ---> i\n",
      "___________capri ---> c\n",
      "__________capric ---> e\n",
      "_________caprice ---> _\n",
      "________________ ---> r\n",
      "_______________r ---> o\n",
      "______________ro ---> w\n",
      "_____________row ---> a\n",
      "____________rowa ---> n\n",
      "___________rowan ---> _\n",
      "________________ ---> k\n",
      "_______________k ---> i\n",
      "______________ki ---> n\n",
      "_____________kin ---> g\n",
      "____________king ---> s\n",
      "___________kings ---> t\n"
     ]
    }
   ],
   "source": [
    "# DATA LOADER\n",
    "context_length = 16\n",
    "\n",
    "def build_dataset(words):\n",
    "    X, Y = [], [] # X = inputs, Y = outputs\n",
    "    for word in words: # [:4] \n",
    "        context = [26] * context_length # _ _ _ word _\n",
    "        for character in word + '_': \n",
    "            index = character_to_index_map[character]\n",
    "            X.append(context)\n",
    "            Y.append(index)\n",
    "            #print(''.join(index_to_character_map[i] for i in context), ' -> ', index_to_character_map[index])\n",
    "            context = context[1:] + [index] # crop first context token and append current token as the new last one of the context\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "# SPLIT DATA INTO TRAIN, DEV, TEST -> 80%, 10%, 10%\n",
    "import random\n",
    "random.shuffle(words)\n",
    "train_num = int(0.8*len(words))\n",
    "dev_num = int(0.9*len(words)) - train_num\n",
    "test_num = len(words) - (train_num + dev_num)\n",
    "print(train_num)\n",
    "print(dev_num)\n",
    "print(test_num)\n",
    "\n",
    "X_train, Y_train = build_dataset(words[:train_num])\n",
    "X_dev, Y_dev = build_dataset(words[train_num:train_num+dev_num])\n",
    "X_test, Y_test = build_dataset(words[train_num+dev_num:])\n",
    "\n",
    "# SANITY CHECK: \n",
    "for x, y in zip(X_train[:20], Y_train[:20]):\n",
    "    print(''.join(index_to_character_map[ix.item()] for ix in x), '--->', index_to_character_map[y.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WaveNet\n",
    "\n",
    "A convolutional architecture to fuse embeddings step by step. \n",
    "\n",
    "![](https://kim.hfg-karlsruhe.de/wp-content/uploads/2018/01/wavenet.png)\n",
    "\n",
    "Why wavenet? -> mlp crushes the whole temporal information to fast together -> idea in wavenet is to step by step fuse the steps and aggregate information this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Layer/Weight Matrix\n",
    "class Linear: \n",
    "    def __init__(self, input_dim, output_dim, bias=True):\n",
    "        self.W = torch.randn((input_dim, output_dim))\n",
    "        self.b = torch.zeros(output_dim) if bias else None\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.W\n",
    "        if self.b is not None:\n",
    "            self.out += self.b\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.W] + ([] if self.b is None else [self.b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Layer -> wrap W (weight matrix) into a class\n",
    "class Embedding: \n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        self.W = torch.randn((vocab_size, embedding_dim))\n",
    "        \n",
    "    def __call__(self, index):\n",
    "        self.out = self.W[index]\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution Layer\n",
    "class FusionLayer1D: # Conv1D\n",
    "    def __init__(self, fusion_size):\n",
    "        self.fusion_size = fusion_size \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        # get dimensions: batch_size, num_tokens, embedding_dim \n",
    "        B, T, C = x.shape\n",
    "        x = x.view(B, T//self.fusion_size, C*self.fusion_size)\n",
    "        if x.shape[1] == 1:\n",
    "            x = x.squeeze(1)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer Stacking Class -> in pytorch this is called nn.Sequential => this is just a container class for layers that are applied sequentially\n",
    "class Sequential: \n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD MODEL\n",
    "embedding_dim = 10\n",
    "hidden_dim = 200\n",
    "vocab_size = num_characters\n",
    "fusion_size = 2 # -> receptive field size = fusion_size * num fusion layers -> in our example we have a total receiptive field of 8 == our context length\n",
    "\n",
    "# example: this is how an MLP would look like from last week\n",
    "mlp_language_model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim), \n",
    "    FusionLayer1D(fusion_size=context_length),\n",
    "    Linear(embedding_dim * context_length, hidden_dim, bias=False), \n",
    "    Tanh(), \n",
    "    Linear(hidden_dim, vocab_size),\n",
    "])\n",
    "\n",
    "# WaveNet/CNN Language Model \n",
    "cnn_language_model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim), \n",
    "    # fusion block 1 -> 16 -> 8\n",
    "    FusionLayer1D(fusion_size=fusion_size),\n",
    "    Linear(embedding_dim * fusion_size, hidden_dim, bias=False),\n",
    "    Tanh(), \n",
    "    # fusion block 1 -> 8 -> 4\n",
    "    FusionLayer1D(fusion_size=fusion_size),\n",
    "    Linear(hidden_dim * fusion_size, hidden_dim, bias=False),\n",
    "    Tanh(), \n",
    "    # fusion block 2 -> 4 -> 2\n",
    "    FusionLayer1D(fusion_size=fusion_size),\n",
    "    Linear(hidden_dim * fusion_size, hidden_dim, bias=False), # important: projected into hidden dimension of 200 here per latent token!\n",
    "    Tanh(), \n",
    "    # fusion block 3 -> 2 -> 1\n",
    "    FusionLayer1D(fusion_size=fusion_size),\n",
    "    Linear(hidden_dim * fusion_size, hidden_dim, bias=False), # important: last layer squeezes out dimension of 1 -> see unsqueeze in fusion layer\n",
    "    Tanh(), \n",
    "    Linear(hidden_dim, vocab_size) # output layer -> given latent vector of input -> predict probability distribution over vocab\n",
    "])\n",
    "\n",
    "\n",
    "# activate gradients for all parameters\n",
    "parameters = cnn_language_model.parameters()\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "    \n",
    "#parameters = mlp_language_model.parameters()\n",
    "#for p in parameters:\n",
    "#    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16])\n",
      "tensor([[26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,  0, 13, 18, 11,  4],\n",
      "        [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 19, 18,  8, 14],\n",
      "        [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,  1,  4, 13],\n",
      "        [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 18,  4]])\n",
      "MLP Language Model: \n",
      "Embedding : (4, 16, 10)\n",
      "FusionLayer1D : (4, 160)\n",
      "Linear : (4, 200)\n",
      "Tanh : (4, 200)\n",
      "Linear : (4, 27)\n",
      "-------------------------------------------------\n",
      "CNN Language Model: \n",
      "Embedding : (4, 16, 10)\n",
      "FusionLayer1D : (4, 8, 20)\n",
      "Linear : (4, 8, 200)\n",
      "Tanh : (4, 8, 200)\n",
      "FusionLayer1D : (4, 4, 400)\n",
      "Linear : (4, 4, 200)\n",
      "Tanh : (4, 4, 200)\n",
      "FusionLayer1D : (4, 2, 400)\n",
      "Linear : (4, 2, 200)\n",
      "Tanh : (4, 2, 200)\n",
      "FusionLayer1D : (4, 400)\n",
      "Linear : (4, 200)\n",
      "Tanh : (4, 200)\n",
      "Linear : (4, 27)\n",
      "torch.Size([4, 27])\n",
      "tensor([  4.6138, -13.3292,  18.4963,  -1.4518,   2.1336,   3.3425,   9.4242,\n",
      "          6.9501,  -3.5200,  -6.5981, -10.1841,  11.5102,  -5.9456,  -2.3177,\n",
      "         -3.4745,  -3.5141,  -6.5925, -11.2439,   4.3942,  -5.1393,  28.9345,\n",
      "        -15.2762,  17.2719, -14.3212,  25.0692,   8.3815,   0.9300],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "# TEST MODEL\n",
    "# take for random examples out of the training set into a batch\n",
    "random_index = torch.randint(0, X_train.shape[0], (4,)) \n",
    "X_batch, Y_batch = X_train[random_index], Y_train[random_index]\n",
    "logits = mlp_language_model(X_batch)\n",
    "logits = cnn_language_model(X_batch)\n",
    "print(X_batch.shape)\n",
    "print(X_batch)\n",
    "\n",
    "# print model architecture\n",
    "print('MLP Language Model: ')  \n",
    "for layer in mlp_language_model.layers:\n",
    "    print(layer.__class__.__name__, ':', tuple(layer.out.shape))\n",
    "    \n",
    "print('-------------------------------------------------')    \n",
    "    \n",
    "# print model architecture\n",
    "print('CNN Language Model: ')  \n",
    "for layer in cnn_language_model.layers:\n",
    "    print(layer.__class__.__name__, ':', tuple(layer.out.shape))\n",
    "    \n",
    "# print logits\n",
    "print(logits.shape)\n",
    "print(logits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/  25000: 32.3277\n",
      "   1000/  25000: 5.7184\n",
      "   2000/  25000: 3.5692\n",
      "   3000/  25000: 3.0771\n",
      "   4000/  25000: 3.2917\n",
      "   5000/  25000: 3.2688\n",
      "   6000/  25000: 2.9839\n",
      "   7000/  25000: 2.6487\n",
      "   8000/  25000: 2.8461\n",
      "   9000/  25000: 2.6585\n",
      "  10000/  25000: 3.0712\n",
      "  11000/  25000: 2.6775\n",
      "  12000/  25000: 2.7514\n",
      "  13000/  25000: 2.5596\n",
      "  14000/  25000: 2.9278\n",
      "  15000/  25000: 2.8302\n",
      "  16000/  25000: 2.6345\n",
      "  17000/  25000: 2.7054\n",
      "  18000/  25000: 2.6886\n",
      "  19000/  25000: 2.6487\n",
      "  20000/  25000: 2.8147\n",
      "  21000/  25000: 2.3881\n",
      "  22000/  25000: 2.6653\n",
      "  23000/  25000: 2.7134\n",
      "  24000/  25000: 2.4967\n"
     ]
    }
   ],
   "source": [
    "# TRAIN MODEL\n",
    "\n",
    "num_epochs = 25000\n",
    "batch_size = 32\n",
    "learning_rate = 0.01\n",
    "lossi = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    # create minibatch\n",
    "    random_indices = torch.randint(0, X_train.shape[0], (batch_size,)) \n",
    "    X_batch, Y_batch = X_train[random_indices], Y_train[random_indices]\n",
    "    \n",
    "    # forward pass\n",
    "    logits = cnn_language_model(X_batch)\n",
    "    loss = F.cross_entropy(logits, Y_batch)\n",
    "    \n",
    "    # backward pass -> zero out gradients\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # update weights -> simple stochastic gradient descent\n",
    "    for p in parameters:\n",
    "        p.data += -learning_rate * p.grad\n",
    "        \n",
    "    # logging\n",
    "    if i % 1000 == 0:\n",
    "        print(f'{i:7d}/{num_epochs:7d}: {loss.item():.4f}')\n",
    "    #lossi.append(loss.log10().item())\n",
    "    lossi.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6387707940>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT training statistics\n",
    "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.708395004272461\n",
      "dev 2.7151899337768555\n",
      "test 2.7115073204040527\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE MODEL \n",
    "\n",
    "# put layers in evaluation mode\n",
    "for layer in cnn_language_model.layers:\n",
    "    layer.training = False\n",
    "\n",
    "@torch.no_grad() # after this decorated gradients are disabled\n",
    "def split_loss(split, model):\n",
    "    x, y = {\n",
    "        'train': (X_train, Y_train), \n",
    "        'dev': (X_dev, Y_dev), \n",
    "        'test': (X_test, Y_test)\n",
    "        }[split]\n",
    "    logits = model(x)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    print(split, loss.item())\n",
    "    \n",
    "split_loss('train', cnn_language_model)\n",
    "split_loss('dev', cnn_language_model)\n",
    "split_loss('test', cnn_language_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lell_\n",
      "eaeio_\n",
      "keaz_\n",
      "aaboma_\n",
      "mfnnaca_\n",
      "rnkikn_\n",
      "nelnnn_\n",
      "aurraa_\n",
      "anuaaln_\n",
      "llinacil_\n"
     ]
    }
   ],
   "source": [
    "# SAMPLING \n",
    "num_words_to_sample = 10\n",
    "\n",
    "for i in range(num_words_to_sample):\n",
    "    model = cnn_language_model\n",
    "    out = []\n",
    "    blank_index = 26 # start with the blank symbol\n",
    "    context = [blank_index] * context_length \n",
    "    while True: \n",
    "        # forward pass \n",
    "        logits = model(torch.tensor([context]))\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        # sample from distribution over characters\n",
    "        index = torch.multinomial(probs, num_samples=1, replacement=True).item()\n",
    "        # shift context to the right\n",
    "        context = context[1:] + [index]\n",
    "        out.append(index_to_character_map[index])\n",
    "        if index == 26: \n",
    "            break \n",
    "    print(''.join(out)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Model Training\n",
    "\n",
    "**Pre-Training:**\n",
    "- Compute Optimal Training -> Chinchilla Paper: https://www.youtube.com/watch?v=TSqkKH4zuZY, https://arxiv.org/abs/2304.03208\n",
    "- cerebras: https://www.cerebras.net/\n",
    "- mosaic: https://www.mosaicml.com/\n",
    "\n",
    "---\n",
    "\n",
    "**Fine-Tuning:**\n",
    "- Low-Rank Adaptation\n",
    "    - PEFT Fine-Tuning\n",
    "    \n",
    "    \n",
    "<img src=\"https://www.philschmid.de/static/blog/fine-tune-flan-t5-peft/thumbnail.png\" alt=\"Image\" width=\"900\" height=\"900\">\n",
    "\n",
    "\n",
    "\n",
    "- Instruction Fine-Tuning\n",
    "    - NIv2: https://instructions.apps.allenai.org/\n",
    "    - Alpaca: https://crfm.stanford.edu/2023/03/13/alpaca.html\n",
    "    - Koala: https://bair.berkeley.edu/blog/2023/04/03/koala/\n",
    "    - EvolInstruct: https://github.com/nlpxucan/WizardLM\n",
    "    - FLAN: https://ai.googleblog.com/2023/02/the-flan-collection-advancing-open.html, https://github.com/lamini-ai/lamini\n",
    " \n",
    " \n",
    "- Dialog/Chat Fine-Tuning\n",
    "    - open assistant: https://huggingface.co/datasets/OpenAssistant/oasst1\n",
    "    - share gpt: https://github.com/domeccleston/sharegpt\n",
    "    \n",
    " \n",
    "- Alignment: \n",
    "    - Reinforcement Learning From Human Feedback: \n",
    "        - anthropic rlhf: https://huggingface.co/datasets/Anthropic/hh-rlhf\n",
    "        \n",
    "---\n",
    "\n",
    "**Model Evaluation:** \n",
    "- Metrics:\n",
    "    - MMLU: https://arxiv.org/abs/2009.03300\n",
    "    - BIGBench: https://arxiv.org/abs/2206.04615\n",
    "    - SuperGLUE: https://arxiv.org/abs/1905.00537\n",
    "- Human Evaluation\n",
    "    - ChatbotArena: https://arena.lmsys.org/\n",
    "- Statistical Methods\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Iterative Adaptation:**\n",
    "- LLM Ops Cycle:\n",
    "\n",
    "<img src=\"./llm_ops_cycle.png\" alt=\"Image\" width=\"700\" height=\"700\">\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions: \n",
    "\n",
    "- Topics of interest for discussion on 26.6.2023 ?\n",
    "    - societal aspects of LLMs \n",
    "    - how to use LLMs ?\n",
    "    - what to regulate? \n",
    "    - LLM cookbook -> how to use LLMs for learning and performance\n",
    "    \n",
    "    - strafmündigkeit von KI\n",
    "        - deepfakes, generated images, \n",
    "            - Schuhmacher ChatGPT Simulation: https://www.digitaltrends.com/computing/ai-generated-schumacher-article-leads-to-editors-dismissal/\n",
    "        - fakenews, desinformation: https://www.tagesschau.de/faktenfinder/ki-desinformation-fakes-101.html\n",
    "            - mögliche lösungen?\n",
    "            - wasserzeichen\n",
    "        - urheberechte? copyrights\n",
    "            - metal: https://www.youtube.com/watch?v=wnfFAFBsg_4\n",
    "            - drake fake\n",
    "        - feeds radikalisieren -> code your own ai\n",
    "     - regulation?  \n",
    "  \n",
    "- Date for presentations (20 min presentation + 3 minute questions)\n",
    "    - suggestion: 19.6 or 26.6\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
