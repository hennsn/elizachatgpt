{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### News\n",
    "\n",
    "- QLORA: https://arxiv.org/abs/2305.14314, \n",
    "    - Tim Dettmers: https://huggingface.co/timdettmers\n",
    "    - Guanaco Model Series: https://guanaco-model.github.io/\n",
    "    - => very large models (65B = 32 bit 200GB, 16 bit 100GB, 8 bit 50 GB, 4bit 25GB) can now run on a 3090 (=24GB), A1600 (=48GB). \n",
    "\n",
    "\n",
    "- RWKV: RNN Transformer Models/Raven Models -> https://www.youtube.com/watch?v=x8pW19wKfXQ, https://arxiv.org/pdf/2305.13048.pdf\n",
    "        \n",
    "- FalconLM tops Llama Models on OS LLM Leaderboard: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard, also 7B (!!!) Parameter Models available + Instruction tuned models!\n",
    "\n",
    "- Finally we know how smart Bard really is: https://chat.lmsys.org/?arena\n",
    "    - impressive: FastChatT5 3B (!!!) almost Bard performance with 3B parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn']\n",
      "num words:  32033\n",
      "len dictinct characters:  26\n",
      "distinct_characters:  ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Num Characters:  27\n",
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25}\n",
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, '_': 26}\n",
      "{0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z', 26: '_'}\n"
     ]
    }
   ],
   "source": [
    "# PREPARE DATA\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# read words from file\n",
    "#words = open('./english_verbs.txt', 'r').read().splitlines()\n",
    "# alternative dataset: https://github.com/dwyl/english-words\n",
    "#words = open('./words_alpha.txt', 'r').read().splitlines()\n",
    "# alternative dataset: german names\n",
    "words = open('./names.txt', 'r').read().splitlines()\n",
    "\n",
    "print(words[:10])\n",
    "\n",
    "print('num words: ', len(words)) \n",
    "\n",
    "# Prepare Alphabet\n",
    "## count characters \n",
    "dataset_characters = []\n",
    "for word in words:\n",
    "    word_characters = list(word) \n",
    "    dataset_characters.extend(word_characters)\n",
    "distinct_characters = sorted(list(set(dataset_characters)))\n",
    "print('len dictinct characters: ', len(distinct_characters))\n",
    "print('distinct_characters: ', distinct_characters)\n",
    "\n",
    "special_characters = ['_'] # changed to blank only for convenience reasons\n",
    "\n",
    "# ngram characters = distinct characters + start token and end token -> + 2 \n",
    "num_characters = len(distinct_characters) + len(special_characters)\n",
    "print('Num Characters: ', num_characters)\n",
    "\n",
    "# create a character to index mapping because it is easier to work with indices when using tensor matrices -> every character gets assigned an index\n",
    "character_to_index_map = {character:index for index, character in enumerate(distinct_characters)}\n",
    "print(character_to_index_map)\n",
    "\n",
    "# add our special characters that symbolize start and end of a word\n",
    "character_to_index_map['_'] = 26\n",
    "print(character_to_index_map)\n",
    "\n",
    "# write characters into the cells to make it look more nicely\n",
    "index_to_character_map = {index:character for character, index in character_to_index_map.items()}\n",
    "print(index_to_character_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25626\n",
      "3203\n",
      "3204\n",
      "torch.Size([182609, 16]) torch.Size([182609])\n",
      "torch.Size([22748, 16]) torch.Size([22748])\n",
      "torch.Size([22789, 16]) torch.Size([22789])\n",
      "________________ ---> u\n",
      "_______________u ---> r\n",
      "______________ur ---> i\n",
      "_____________uri ---> _\n",
      "________________ ---> k\n",
      "_______________k ---> o\n",
      "______________ko ---> n\n",
      "_____________kon ---> s\n",
      "____________kons ---> t\n",
      "___________konst ---> a\n",
      "__________konsta ---> n\n",
      "_________konstan ---> t\n",
      "________konstant ---> i\n",
      "_______konstanti ---> n\n",
      "______konstantin ---> e\n",
      "_____konstantine ---> _\n",
      "________________ ---> m\n",
      "_______________m ---> a\n",
      "______________ma ---> c\n",
      "_____________mac ---> k\n"
     ]
    }
   ],
   "source": [
    "# DATA LOADER\n",
    "context_length = 16\n",
    "\n",
    "def build_dataset(words):\n",
    "    X, Y = [], [] # X = inputs, Y = outputs\n",
    "    for word in words: # [:4] \n",
    "        context = [26] * context_length # _ _ _ word _\n",
    "        for character in word + '_': \n",
    "            index = character_to_index_map[character]\n",
    "            X.append(context)\n",
    "            Y.append(index)\n",
    "            #print(''.join(index_to_character_map[i] for i in context), ' -> ', index_to_character_map[index])\n",
    "            context = context[1:] + [index] # crop first context token and append current token as the new last one of the context\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "# SPLIT DATA INTO TRAIN, DEV, TEST -> 80%, 10%, 10%\n",
    "import random\n",
    "random.shuffle(words)\n",
    "train_num = int(0.8*len(words))\n",
    "dev_num = int(0.9*len(words)) - train_num\n",
    "test_num = len(words) - (train_num + dev_num)\n",
    "print(train_num)\n",
    "print(dev_num)\n",
    "print(test_num)\n",
    "\n",
    "X_train, Y_train = build_dataset(words[:train_num])\n",
    "X_dev, Y_dev = build_dataset(words[train_num:train_num+dev_num])\n",
    "X_test, Y_test = build_dataset(words[train_num+dev_num:])\n",
    "\n",
    "# SANITY CHECK: \n",
    "for x, y in zip(X_train[:20], Y_train[:20]):\n",
    "    print(''.join(index_to_character_map[ix.item()] for ix in x), '--->', index_to_character_map[y.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Networks\n",
    "\n",
    "![](https://gamedevacademy.org/wp-content/uploads/2017/10/Unrolled-RNN.png.webp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class RNNCell(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim): \n",
    "        super().__init__()\n",
    "        self.xh_to_h = nn.Linear(embedding_dim + hidden_dim, hidden_dim) # RNN -> GRU, LSTM\n",
    "        # optional -> per state lm head to classify output\n",
    "\n",
    "    def forward(self, xt, hprev):\n",
    "        xh = torch.cat([xt, hprev], dim=1)\n",
    "        ht = F.tanh(self.xh_to_h(xh))\n",
    "        return ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, context_length, vocab_size, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.context_length = context_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.start = nn.Parameter(torch.zeros(1, hidden_dim)) # the starting hidden state\n",
    "        self.embedding_layer = nn.Embedding(self.vocab_size, embedding_dim) # token embeddings table\n",
    "        self.cell = RNNCell(embedding_dim, hidden_dim)\n",
    "        self.lm_head = nn.Linear(hidden_dim, self.vocab_size)\n",
    "\n",
    "    def get_context_length(self):\n",
    "        return self.context_length  \n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        b, t = idx.size()\n",
    "        \n",
    "        # embed all the integers up front and all at once for efficiency\n",
    "        emb = self.embedding_layer(idx) # (b, t, n_embd)\n",
    "\n",
    "        # sequentially iterate over the inputs and update the RNN state each tick\n",
    "        hprev = self.start.expand((b, -1)) # expand out the batch dimension\n",
    "        hiddens = []\n",
    "        for i in range(t): # Transformer -> T-Layer -> # Residual Connections # Attention?!\n",
    "            xt = emb[:, i, :] # (b, n_embd)\n",
    "            ht = self.cell(xt, hprev) # (b, n_embd2)\n",
    "            hprev = ht\n",
    "            hiddens.append(ht)\n",
    "\n",
    "        # decode the outputs\n",
    "        hidden = torch.stack(hiddens, 1) # (b, t, n_embd2)\n",
    "        logits = self.lm_head(hidden)\n",
    "        \n",
    "        # take last step logits out for next token prediction objective\n",
    "        logits = logits[:, -1, :]\n",
    "        \n",
    "        # if we are given some desired targets also calculate the loss\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits, targets.view(-1), ignore_index=-1)\n",
    "            \n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "embedding_dim = 10\n",
    "hidden_dim = 200\n",
    "vocab_size = num_characters\n",
    "context_length = 16\n",
    "learning_rate = 5e-4\n",
    "weight_decay = 0.01\n",
    "\n",
    "# define language model\n",
    "rnn_language_model = RNN(context_length, vocab_size, embedding_dim, hidden_dim)\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.AdamW(rnn_language_model.parameters(), lr=learning_rate, weight_decay=weight_decay, betas=(0.9, 0.99), eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1698: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/    500: 3.3240\n",
      "    100/    500: 2.6924\n",
      "    200/    500: 2.5648\n",
      "    300/    500: 2.7195\n",
      "    400/    500: 2.6081\n"
     ]
    }
   ],
   "source": [
    "# TRAIN MODEL\n",
    "num_epochs = 500\n",
    "batch_size = 32\n",
    "learning_rate = 0.01\n",
    "lossi = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    # create minibatch\n",
    "    random_indices = torch.randint(0, X_train.shape[0], (batch_size,)) \n",
    "    X_batch, Y_batch = X_train[random_indices], Y_train[random_indices]\n",
    "    \n",
    "    # forward pass\n",
    "    logits, loss = rnn_language_model(X_batch, Y_batch)\n",
    "    \n",
    "    # backward pass -> zero out gradients \n",
    "    optimizer.zero_grad() # model.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    \n",
    "    # update weights -> simple stochastic gradient descent\n",
    "    optimizer.step()\n",
    "        \n",
    "    # logging\n",
    "    if i % 100 == 0:\n",
    "        print(f'{i:7d}/{num_epochs:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4163ee4640>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT training statistics\n",
    "plt.plot(torch.tensor(lossi).view(-1, 100).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1698: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.487360715866089\n",
      "dev 2.481539249420166\n",
      "test 2.4903604984283447\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE MODEL \n",
    "\n",
    "@torch.no_grad() # after this decorated gradients are disabled\n",
    "def split_loss(split, model):\n",
    "    x, y = {\n",
    "        'train': (X_train, Y_train), \n",
    "        'dev': (X_dev, Y_dev), \n",
    "        'test': (X_test, Y_test)\n",
    "        }[split]\n",
    "    logits, loss = model(x, y)\n",
    "    print(split, loss.item())\n",
    "    \n",
    "split_loss('train', rnn_language_model)\n",
    "split_loss('dev', rnn_language_model)\n",
    "split_loss('test', rnn_language_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oheln_\n",
      "rilidy_\n",
      "suca_\n",
      "eubrln_\n",
      "eritv_\n",
      "sadhm_\n",
      "acanne_\n",
      "noxe_\n",
      "jlmil_\n",
      "kycian_\n"
     ]
    }
   ],
   "source": [
    "# SAMPLING \n",
    "num_words_to_sample = 10\n",
    "\n",
    "for i in range(num_words_to_sample):\n",
    "    model = rnn_language_model\n",
    "    out = []\n",
    "    blank_index = 26 # start with the blank symbol\n",
    "    context = [blank_index] * context_length \n",
    "    while True: \n",
    "        # forward pass \n",
    "        logits, _ = model(torch.tensor([context]))\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        # sample from distribution over characters\n",
    "        index = torch.multinomial(probs, num_samples=1, replacement=True).item()\n",
    "        # shift context to the right\n",
    "        context = context[1:] + [index]\n",
    "        out.append(index_to_character_map[index])\n",
    "        if index == 26: \n",
    "            break \n",
    "    print(''.join(out)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deployment\n",
    "\n",
    "# libs: mediapipe, dlib\n",
    "\n",
    "# kivy -> webapp\n",
    "\n",
    "# docker -> docker auf handy\n",
    "\n",
    "# webapp -> webassembly \n",
    "\n",
    "# kotlin/java -> performance? \n",
    "\n",
    "# Unity? + Plugin\n",
    "\n",
    "# -> decision tree presentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
